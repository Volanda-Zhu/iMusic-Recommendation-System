{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>4</td><td>application_1606841923384_0005</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-80-132.ec2.internal:20888/proxy/application_1606841923384_0005/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-90-149.ec2.internal:8042/node/containerlogs/container_1606841923384_0005_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1000M'"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.getConf().get('spark.driver.memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1606841923384_0006</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-80-132.ec2.internal:20888/proxy/application_1606841923384_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-83-192.ec2.internal:8042/node/containerlogs/container_1606841923384_0006_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'driverMemory': '8000M', 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1606841923384_0006</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-80-132.ec2.internal:20888/proxy/application_1606841923384_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-83-192.ec2.internal:8042/node/containerlogs/container_1606841923384_0006_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f \n",
    "{\"driverMemory\": \"8000M\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.us-east-1.amazonaws.com\")\n",
    "sqlContext = SQLContext(sc)\n",
    "match = sqlContext.read.format('com.databricks.spark.csv').option('delimiter', '\\t').load('s3://millionsongprocessed/train_triplets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'8000M'"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.getConf().get('spark.driver.memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---+\n",
      "|                 _c0|               _c1|_c2|\n",
      "+--------------------+------------------+---+\n",
      "|b80344d063b5ccb32...|SOAKIMP12A8C130995|  1|\n",
      "|b80344d063b5ccb32...|SOAPDEY12A81C210A9|  1|\n",
      "|b80344d063b5ccb32...|SOBBMDR12A8C13253B|  2|\n",
      "|b80344d063b5ccb32...|SOBFNSP12AF72A0E22|  1|\n",
      "|b80344d063b5ccb32...|SOBFOVM12A58A7D494|  1|\n",
      "|b80344d063b5ccb32...|SOBNZDC12A6D4FC103|  1|\n",
      "|b80344d063b5ccb32...|SOBSUJE12A6D4F8CF5|  2|\n",
      "|b80344d063b5ccb32...|SOBVFZR12A6D4F8AE3|  1|\n",
      "|b80344d063b5ccb32...|SOBXALG12A8C13C108|  1|\n",
      "|b80344d063b5ccb32...|SOBXHDL12A81C204C0|  1|\n",
      "+--------------------+------------------+---+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "match.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "match = match.rdd.map(lambda p: (p[0], p[1], int(p[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, StringType, StructField, StructType\n",
    "schemaTaste = StructType([StructField(\"user\", StringType(), True), StructField(\"song\", StringType(), True), StructField(\"playCount\", IntegerType(), True)])\n",
    "dfTaste = sqlContext.createDataFrame(match, schema=schemaTaste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---------+\n",
      "|                user|              song|playCount|\n",
      "+--------------------+------------------+---------+\n",
      "|b80344d063b5ccb32...|SOAKIMP12A8C130995|        1|\n",
      "|b80344d063b5ccb32...|SOAPDEY12A81C210A9|        1|\n",
      "|b80344d063b5ccb32...|SOBBMDR12A8C13253B|        2|\n",
      "|b80344d063b5ccb32...|SOBFNSP12AF72A0E22|        1|\n",
      "|b80344d063b5ccb32...|SOBFOVM12A58A7D494|        1|\n",
      "|b80344d063b5ccb32...|SOBNZDC12A6D4FC103|        1|\n",
      "|b80344d063b5ccb32...|SOBSUJE12A6D4F8CF5|        2|\n",
      "|b80344d063b5ccb32...|SOBVFZR12A6D4F8AE3|        1|\n",
      "|b80344d063b5ccb32...|SOBXALG12A8C13C108|        1|\n",
      "|b80344d063b5ccb32...|SOBXHDL12A81C204C0|        1|\n",
      "+--------------------+------------------+---------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "dfTaste.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 1019318\n",
      "Number of unique songs: 384546"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# change ids from strings to integers\n",
    "user_change = dfTaste.select('user').distinct().select('user', F.monotonically_increasing_id().alias('new_user'))\n",
    "song_change = dfTaste.select('song').distinct().select('song', F.monotonically_increasing_id().alias('new_song'))\n",
    "\n",
    "# get total unique users and songs\n",
    "unique_users = user_change.count()\n",
    "unique_songs = song_change.count()\n",
    "print('Number of unique users: {0}'.format(unique_users))\n",
    "print('Number of unique songs: {0}'.format(unique_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---------+----------+----------+\n",
      "|                user|              song|playCount|user_index|song_index|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "|b80344d063b5ccb32...|SOAKIMP12A8C130995|        1|  103159.0|    2979.0|\n",
      "|b80344d063b5ccb32...|SOAPDEY12A81C210A9|        1|  103159.0|   12804.0|\n",
      "|b80344d063b5ccb32...|SOBBMDR12A8C13253B|        2|  103159.0|    3509.0|\n",
      "|b80344d063b5ccb32...|SOBFNSP12AF72A0E22|        1|  103159.0|   31957.0|\n",
      "|b80344d063b5ccb32...|SOBFOVM12A58A7D494|        1|  103159.0|   20788.0|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "# Run string indexer on serveral column\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(dfTaste) for column in [\"user\", \"song\"]]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "dfTaste_idx = pipeline.fit(dfTaste).transform(dfTaste)\n",
    "\n",
    "dfTaste_idx.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cast index column to Integer\n",
    "dfTaste_idx = dfTaste_idx.withColumn(\"user_index\", dfTaste_idx['user_index'].cast(IntegerType()))\n",
    "dfTaste_idx = dfTaste_idx.withColumn(\"song_index\", dfTaste_idx['song_index'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---------+----------+----------+\n",
      "|                user|              song|playCount|user_index|song_index|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "|b80344d063b5ccb32...|SOAKIMP12A8C130995|        1|    103159|      2979|\n",
      "|b80344d063b5ccb32...|SOAPDEY12A81C210A9|        1|    103159|     12804|\n",
      "|b80344d063b5ccb32...|SOBBMDR12A8C13253B|        2|    103159|      3509|\n",
      "|b80344d063b5ccb32...|SOBFNSP12AF72A0E22|        1|    103159|     31957|\n",
      "|b80344d063b5ccb32...|SOBFOVM12A58A7D494|        1|    103159|     20788|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# cache\n",
    "tasteDf_with_songId = dfTaste_idx\n",
    "tasteDf_with_songId.cache()\n",
    "tasteDf_with_songId.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 29020730, validation: 9674561, test: 9678295\n",
      "\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "|                user|              song|playCount|user_index|song_index|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "|00003a4459f33b929...|SOCEQVU12A6D4F78B3|        3|    753452|     22550|\n",
      "|00003a4459f33b929...|SOEOODW12AB017A9FB|        1|    753452|    131979|\n",
      "|00003a4459f33b929...|SOMZHIH12A8AE45D00|        3|    753452|      5527|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "|                user|              song|playCount|user_index|song_index|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "|00003a4459f33b929...|SOJTVUM12AB018CB60|        1|    753452|    108742|\n",
      "|00003a4459f33b929...|SOMZIQI12AB017F9B8|        1|    753452|    112271|\n",
      "|00005c6177188f12f...|SOGNVXA12A8C14373F|        1|    772245|      7240|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "|                user|              song|playCount|user_index|song_index|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "|00003a4459f33b929...|SOAUMDO12AB018E210|        1|    753452|    149779|\n",
      "|00003a4459f33b929...|SOJJRVI12A6D4FBE49|        1|    753452|      3137|\n",
      "|00003a4459f33b929...|SOKJWZB12A6D4F9487|        4|    753452|      8986|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "# We'll hold out 60% for training, 20% of our data for validation, and leave 20% for testing\n",
    "seed = 0\n",
    "(split_60_df, split_a_20_df, split_b_20_df) = tasteDf_with_songId.randomSplit([0.6, 0.2, 0.2], seed = seed)\n",
    "\n",
    "# Let's cache these datasets for performance\n",
    "training_df = split_60_df.cache()\n",
    "validation_df = split_a_20_df.cache()\n",
    "test_df = split_b_20_df.cache()\n",
    "\n",
    "print('Training: {0}, validation: {1}, test: {2}\\n'.format(\n",
    "  training_df.count(), validation_df.count(), test_df.count())\n",
    ")\n",
    "training_df.show(3)\n",
    "validation_df.show(3)\n",
    "test_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---------+----------+----------+\n",
      "|                user|              song|playCount|user_index|song_index|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "|00003a4459f33b929...|SOJTVUM12AB018CB60|      1.0|    753452|    108742|\n",
      "|00003a4459f33b929...|SOMZIQI12AB017F9B8|      1.0|    753452|    112271|\n",
      "|00005c6177188f12f...|SOGNVXA12A8C14373F|      1.0|    772245|      7240|\n",
      "|00005c6177188f12f...|SORGGRV12A8AE477C0|      2.0|    772245|      6714|\n",
      "|00030033e3a2f904a...|SOBEAKR12A6701F536|      3.0|    756373|     20130|\n",
      "|00030033e3a2f904a...|SOWCEQC12AF72A2B64|      2.0|    756373|     16308|\n",
      "|00030033e3a2f904a...|SOXJFKD12A3F1EA31A|      1.0|    756373|     11332|\n",
      "|00030033e3a2f904a...|SOXNYUA12AB017B49B|      3.0|    756373|       767|\n",
      "|00030033e3a2f904a...|SOXQWUS12A58A7B236|      1.0|    756373|      1187|\n",
      "|0007c0e74728ca9ef...|SODMFNK12AF72A2A27|      1.0|    861308|     10393|\n",
      "+--------------------+------------------+---------+----------+----------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "#Number of plays needs to be double type, not integers\n",
    "validation_df = validation_df.withColumn(\"playCount\", validation_df[\"playCount\"].cast(DoubleType()))\n",
    "validation_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alternating least squares\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Let's initialize our ALS learner\n",
    "als = ALS()\n",
    "\n",
    "# Now set the parameters for the method\n",
    "als.setMaxIter(3)\\\n",
    "   .setSeed(seed)\\\n",
    "   .setItemCol(\"song_index\")\\\n",
    "   .setRatingCol(\"playCount\")\\\n",
    "   .setUserCol(\"user_index\")\n",
    "\n",
    "# Create regression evaluator\n",
    "reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"playCount\", metricName=\"rmse\")\n",
    "\n",
    "# Hyperparameter tuning to find best rank and reg param\n",
    "tolerance = 0.03\n",
    "ranks = [4, 8, 12]\n",
    "regParams = [0.15, 0.2]\n",
    "errors = [[0]*len(ranks)]*len(regParams)\n",
    "models = [[0]*len(ranks)]*len(regParams)\n",
    "err = 0\n",
    "min_error = float('inf')\n",
    "best_rank = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4, regularization parameter 0.15 the RMSE is 7.600068841594392\n",
      "For rank 8, regularization parameter 0.15 the RMSE is 7.4837036338836445\n",
      "For rank 12, regularization parameter 0.15 the RMSE is 7.318356017861835\n",
      "For rank 4, regularization parameter 0.2 the RMSE is 7.4694363719117\n",
      "For rank 8, regularization parameter 0.2 the RMSE is 7.338156714784233\n",
      "For rank 12, regularization parameter 0.2 the RMSE is 7.2012332572684965"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for regParam in regParams:\n",
    "    j = 0\n",
    "    for rank in ranks:\n",
    "        \n",
    "        # Set the rank here:\n",
    "        als.setParams(rank = rank, regParam = regParam)\n",
    "        # Create the model with these parameters.\n",
    "        model = als.fit(training_df)\n",
    "        # Run the model to create a prediction. Predict against the validation_df.\n",
    "        predict_df = model.transform(validation_df)\n",
    "        # Remove NaN values from prediction (due to SPARK-14489)\n",
    "        predicted_plays_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "        predicted_plays_df = predicted_plays_df.withColumn(\"prediction\", F.abs(F.round(predicted_plays_df[\"prediction\"],0)))\n",
    "        # Run the previously created RMSE evaluator, reg_eval, on the predicted_ratings_df DataFrame\n",
    "        error = reg_eval.evaluate(predicted_plays_df)\n",
    "        errors[i][j] = error\n",
    "        models[i][j] = model\n",
    "        print ('For rank %s, regularization parameter %s the RMSE is %s' % (rank, regParam, error))\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_params = [i,j]\n",
    "        j += 1\n",
    "    i += 1\n",
    "\n",
    "als.setRegParam(regParams[best_params[0]])\n",
    "als.setRank(ranks[best_params[1]])\n",
    "# print ('The best model was trained with regularization parameter %s' % regParams[best_params[0]])\n",
    "# print ('The best model was trained with rank %s' % ranks[best_params[1]])\n",
    "my_model = models[best_params[0]][best_params[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---------+----------+----------+----------+\n",
      "|                user|              song|playCount|user_index|song_index|prediction|\n",
      "+--------------------+------------------+---------+----------+----------+----------+\n",
      "|7e2a2bbe97568dfce...|SOUVTSM12AC468F6A7|      1.0|       334|        12|       1.0|\n",
      "|3ffb4ea1467ad4549...|SOUVTSM12AC468F6A7|      2.0|       977|        12|       1.0|\n",
      "|e4b426ac0d1cb8ec2...|SOUVTSM12AC468F6A7|      7.0|      1760|        12|       1.0|\n",
      "|285f4d3965daa1275...|SOUVTSM12AC468F6A7|      3.0|      2615|        12|       1.0|\n",
      "|2fff793ffc36da7fc...|SOUVTSM12AC468F6A7|      6.0|      2858|        12|       2.0|\n",
      "|cb650779e089ac8d3...|SOUVTSM12AC468F6A7|      2.0|      4358|        12|       1.0|\n",
      "|583be18f53885bd02...|SOUVTSM12AC468F6A7|      1.0|      4456|        12|       2.0|\n",
      "|620983c7b1b25bb6b...|SOUVTSM12AC468F6A7|      3.0|      6812|        12|       1.0|\n",
      "|573bef8f7c4d79269...|SOUVTSM12AC468F6A7|      1.0|      8099|        12|       1.0|\n",
      "|3566b5f86d607bdfa...|SOUVTSM12AC468F6A7|      1.0|      8302|        12|       2.0|\n",
      "+--------------------+------------------+---------+----------+----------+----------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "predicted_plays_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a RMSE on the test set of 6.2977267068362535"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "# In ML Pipelines, this next step has a bug that produces unwanted NaN values. We\n",
    "# have to filter them out. See https://issues.apache.org/jira/browse/SPARK-14489\n",
    "\n",
    "test_df = test_df.withColumn(\"playCount\", test_df[\"playCount\"].cast(DoubleType()))\n",
    "predict_df = my_model.transform(test_df)\n",
    "\n",
    "# Remove NaN values from prediction (due to SPARK-14489)\n",
    "predicted_test_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "\n",
    "# Round floats to whole numbers\n",
    "predicted_test_df = predicted_test_df.withColumn(\"prediction\", F.abs(F.round(predicted_test_df[\"prediction\"],0)))\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_df DataFrame\n",
    "test_RMSE = reg_eval.evaluate(predicted_test_df)\n",
    "\n",
    "print('The model had a RMSE on the test set of {0}'.format(test_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|round(avg(playCount), 0)|\n",
      "+------------------------+\n",
      "|                     3.0|\n",
      "+------------------------+\n",
      "\n",
      "The average number of plays in the dataset is 3.0\n",
      "The RMSE on the average set is 6.175594688452001"
     ]
    }
   ],
   "source": [
    "# Comparing the model with the error from a test set where every rating is the averge number of plays from the training set\n",
    "avg_plays_df = training_df.groupBy().avg('playCount').select(F.round('avg(playCount)'))\n",
    "\n",
    "avg_plays_df.show(3)\n",
    "# Extract the average rating value. (This is row 0, column 0.)\n",
    "training_avg_plays = avg_plays_df.collect()[0][0]\n",
    "\n",
    "print('The average number of plays in the dataset is {0}'.format(training_avg_plays))\n",
    "\n",
    "# Add a column with the average rating\n",
    "test_for_avg_df = test_df.withColumn('prediction', F.lit(training_avg_plays))\n",
    "\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the test_for_avg_df DataFrame\n",
    "test_avg_RMSE = reg_eval.evaluate(test_for_avg_df)\n",
    "\n",
    "print(\"The RMSE on the average set is {0}\".format(test_avg_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
